{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key Components to Implement**\n",
    "1. **Recurrent Neural Networks (RNNs)**:\n",
    "   - Two layers: Sensory layer and M1 layer.\n",
    "   - Sensory layer processes proprioceptive feedback.\n",
    "   - M1 layer generates descending commands to muscles.\n",
    "\n",
    "2. **Spinal Reflex**:\n",
    "   - Afferent feedback from muscle kinematics (length, velocity, acceleration, jerk).\n",
    "   - Reflex gain applied to the afferent feedback.\n",
    "\n",
    "3. **Muscle Activation Dynamics**:\n",
    "   - Combines descending commands from M1 and spinal reflex.\n",
    "   - Includes time delays for neural and spinal reflex pathways.\n",
    "\n",
    "4. **Musculoskeletal Model**:\n",
    "   - Two-segment arm with six muscles.\n",
    "   - Muscle activations produce forces, which generate joint torques and motion.\n",
    "\n",
    "5. **Feedback Loop**:\n",
    "   - Joint angles, velocities, and muscle states are fed back to the RNNs and spinal reflex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **1. Sensory Layer (`y_s`)**\n",
    "- **Description**: Represents the sensory cortex, which processes sensory feedback (`u_fb`).\n",
    "- **Number of Units**: `n_s = 200` (as per the researchers' description).\n",
    "- **Shape**: `[n_s]` or `[200]` (a 1D tensor with 200 elements).\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Motor Layer (`y_m`)**\n",
    "- **Description**: Represents the motor cortex, which generates descending commands to muscles.\n",
    "- **Number of Units**: `n_m1 = 200` (as per the researchers' description).\n",
    "- **Shape**: `[n_m1]` or `[200]` (a 1D tensor with 200 elements).\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Muscle Activation Layer (`y_act`)**\n",
    "- **Description**: Projects the motor cortex output to the muscles. The number of units matches the number of muscles.\n",
    "- **Number of Units**: `n_muscles = 6` (6 muscles in the `myoElbow` model).\n",
    "- **Shape**: `[n_muscles]` or `[6]` (a 1D tensor with 6 elements).\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Feedback Input (`u_fb`)**\n",
    "- **Description**: Proprioceptive feedback, including joint angles, velocities, and muscle forces.\n",
    "- **Components**:\n",
    "  - `θ_d(t)`: Delayed joint angles (e.g., shoulder and elbow).\n",
    "  - `θ_g`: Goal joint angles.\n",
    "  - `F_m`: Muscle forces (6 muscles).\n",
    "- **Shape**: `[n_inputs]` or `[9]` (2 joint angles + 2 joint velocities + 6 muscle forces).\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Afferent Feedback (`x_aff`)**\n",
    "- **Description**: Encodes muscle kinematics (length, velocity, acceleration, jerk) for each muscle.\n",
    "- **Components**:\n",
    "  - `Δx_ml`: Muscle length changes.\n",
    "  - `x_mv`: Muscle velocities.\n",
    "  - `x_ma`: Muscle accelerations.\n",
    "  - `x_mj`: Muscle jerks.\n",
    "- **Shape**: `[n_muscles, 4]` or `[6, 4]` (6 muscles × 4 kinematic states).\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Weight Matrices**\n",
    "- **Sensory Layer Weights (`w_sr`, `w_si`)**:\n",
    "  - `w_sr`: Recurrent weights for the sensory layer.\n",
    "    - Shape: `[n_s, n_s]` or `[200, 200]`.\n",
    "  - `w_si`: Weights connecting sensory feedback to the sensory layer.\n",
    "    - Shape: `[n_s, n_inputs]` or `[200, 9]`.\n",
    "\n",
    "- **Motor Layer Weights (`w_mr`, `w_mi`)**:\n",
    "  - `w_mr`: Recurrent weights for the motor layer.\n",
    "    - Shape: `[n_m1, n_m1]` or `[200, 200]`.\n",
    "  - `w_mi`: Weights connecting the sensory layer to the motor layer.\n",
    "    - Shape: `[n_m1, n_s]` or `[200, 200]`.\n",
    "\n",
    "- **Muscle Activation Weights (`w_act`)**:\n",
    "  - Weights connecting the motor layer to the muscle activation layer.\n",
    "    - Shape: `[n_muscles, n_m1]` or `[6, 200]`.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Bias Terms**\n",
    "- **Sensory Layer Bias (`b_s`)**:\n",
    "  - Shape: `[n_s]` or `[200]`.\n",
    "- **Motor Layer Bias (`b_m`)**:\n",
    "  - Shape: `[n_m1]` or `[200]`.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Reflex Parameters**\n",
    "- **Stretch Reflex Gain (`G_s`)**:\n",
    "  - Scalar value (e.g., `0.8` or `1.9`).\n",
    "- **Afferent Encoding Gains (`G_aff`)**:\n",
    "  - Shape: `[4]` (for length, velocity, acceleration, jerk).\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Neural Dynamics**\n",
    "- **Sensory Layer Dynamics**:\n",
    "  - `y_s(t+Δt) = (1-(Δt/τ_n))*y_s(t) + (Δt/τ_n) * tanh(u_s(t))`\n",
    "  - Shape of `y_s`: `[n_s]` or `[200]`.\n",
    "- **Motor Layer Dynamics**:\n",
    "  - `y_m(t+Δt) = (1-(Δt/τ_n))*y_m(t) + (Δt/τ_n) * tanh(u_m(t))`\n",
    "  - Shape of `y_m`: `[n_m1]` or `[200]`.\n",
    "- **Muscle Activation Dynamics**:\n",
    "  - `y_act(t+Δt) = (1-(Δt/τ_m))*y_act(t) + (Δt/τ_m) * ReLU(u_act(t))`\n",
    "  - Shape of `y_act`: `[n_muscles]` or `[6]`.\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Observation (`obs`)**\n",
    "- **Description**: The observation returned by the environment.\n",
    "- **Components**:\n",
    "  - `qpos`: Joint positions (e.g., shoulder and elbow).\n",
    "  - `qvel`: Joint velocities.\n",
    "  - `act`: Muscle activations.\n",
    "  - `pose_err`: Pose error.\n",
    "- **Shape**: `[9]` (as per the `myoElbow` environment).\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary of Shapes**\n",
    "\n",
    "| Component                  | Shape         | Description                                      |\n",
    "|----------------------------|---------------|--------------------------------------------------|\n",
    "| `y_s` (Sensory Layer)      | `[200]`       | Sensory cortex output.                          |\n",
    "| `y_m` (Motor Layer)        | `[200]`       | Motor cortex output.                            |\n",
    "| `y_act` (Muscle Activation)| `[6]`         | Muscle activation output.                       |\n",
    "| `u_fb` (Feedback Input)    | `[9]`         | Proprioceptive feedback.                        |\n",
    "| `x_aff` (Afferent Feedback)| `[6, 4]`      | Muscle kinematics (length, velocity, etc.).     |\n",
    "| `w_sr`                    | `[200, 200]`  | Sensory layer recurrent weights.               |\n",
    "| `w_si`                    | `[200, 9]`    | Sensory feedback to sensory layer weights.      |\n",
    "| `w_mr`                    | `[200, 200]`  | Motor layer recurrent weights.                 |\n",
    "| `w_mi`                    | `[200, 200]`  | Sensory layer to motor layer weights.           |\n",
    "| `w_act`                   | `[6, 200]`    | Motor layer to muscle activation weights.       |\n",
    "| `b_s` (Sensory Bias)       | `[200]`       | Sensory layer bias.                             |\n",
    "| `b_m` (Motor Bias)         | `[200]`       | Motor layer bias.                               |\n",
    "| `G_s`                     | `scalar`      | Stretch reflex gain.                            |\n",
    "| `G_aff`                   | `[4]`         | Afferent encoding gains.                        |\n",
    "| `obs`                     | `[9]`         | Observation from the environment.               |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyoSuite:> Registering Myo Envs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/opensim_scripting/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoArmReachFixed-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/opt/anaconda3/envs/opensim_scripting/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoSarcArmReachFixed-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/opt/anaconda3/envs/opensim_scripting/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoFatiArmReachFixed-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/opt/anaconda3/envs/opensim_scripting/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoArmReachRandom-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/opt/anaconda3/envs/opensim_scripting/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoSarcArmReachRandom-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/opt/anaconda3/envs/opensim_scripting/lib/python3.11/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment myoFatiArmReachRandom-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import myosuite\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulation parameters ---\n",
    "dt = 0.01       # Time step (10 ms)\n",
    "tau_n = 0.02    # Neuron time constant (20 ms)\n",
    "tau_m = 0.05    # Muscle time constant (50 ms)\n",
    "\n",
    "# --- Neural network parameters ---\n",
    "n_s = 200       # Number of sensory neurons\n",
    "n_m1 = 200      # Number of motor neurons\n",
    "n_muscles = 6   # Number of muscles\n",
    "n_inputs = 10   # Size of proprioceptive feedback (from myoElbow observation)\n",
    "\n",
    "# --- Feedback gains ---\n",
    "G_p = 1.0       # Gain for position error\n",
    "G_d = 1.0       # Gain for velocity\n",
    "G_f = 1.0       # Gain for muscle forces\n",
    "\n",
    "# --- Reflex parameters ---\n",
    "G_aff = torch.tensor([1, 0.1, 0.01, 0.0001])  # Encoding gains for length, velocity, acceleration, jerk\n",
    "G_s_low = 0.8                                 # Spinal reflex gain (low reflex gain)\n",
    "G_s_high = 1.9                                # Spinal reflex gain (high reflex gain)\n",
    "reflex_delay = int(0.02 / dt)                 # Spinal reflex delay (20 ms)\n",
    "\n",
    "# --- Transcortical afferent delay ---\n",
    "feedback_delay_steps = int(0.04 / dt)         # Transcortical afferent delay (40 ms)\n",
    "\n",
    "# --- Movement arm matrix (Mm) ---\n",
    "# TODO: Extract these values from myoElbow model directly\n",
    "M_m = torch.tensor([\n",
    "    [0.05, 0.0],  # Muscle 1 (shoulder flexor)\n",
    "    [0.05, 0.0],  # Muscle 2 (shoulder extensor)\n",
    "    [0.0, 0.04],  # Muscle 3 (elbow flexor)\n",
    "    [0.0, 0.04],  # Muscle 4 (elbow extensor)\n",
    "    [0.03, 0.03], # Muscle 5 (biarticular biceps)\n",
    "    [0.03, 0.03]  # Muscle 6 (biarticular triceps)\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# --- Target joint positions ---\n",
    "target_qpos = torch.tensor([1.5, 1.0], dtype=torch.float32)  # Desired joint positions (shoulder, elbow)\n",
    "\n",
    "# --- Penalty coefficients for cost function ---\n",
    "alpha = 0.0001  # Penalizes neural activity\n",
    "beta = 0.01     # Penalizes force output\n",
    "gamma = 0.5     # Penalizes kinematic error\n",
    "\n",
    "# --- Time parameters for background and perturbation loads ---\n",
    "Tb = 200 / 1000    # Background load onset (200 ms)\n",
    "Tp = 1500 / 1000   # Perturbation load onset (1500 ms)\n",
    "T = 3000 / 1000    # Total motion time (3000 ms)\n",
    "Tsb = 1000 / 1000  # Steady-state realization of background load (1000 ms)\n",
    "Tsp = 2500 / 1000  # Steady-state realization of perturbation load (2500 ms)\n",
    "\n",
    "# --- External loads ---\n",
    "background_load_low = 0.1    # Low background load (Nm)\n",
    "background_load_high = 0.55  # High background load (Nm)\n",
    "perturbation_load = 0.25     # Perturbation load (Nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m    MyoSuite: A contact-rich simulation suite for musculoskeletal motor control\n",
      "        Vittorio Caggiano, Huawei Wang, Guillaume Durandau, Massimo Sartori, Vikash Kumar\n",
      "        L4DC-2019 | https://sites.google.com/view/myosuite\n",
      "    \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MyoArm environment\n",
    "env = gym.make(\"myoArmReachFixed-v0\")\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random action\n",
    "action = env.action_space.sample()\n",
    "obs, reward, terminated, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Joint positions (obs):\", obs[:20])\n",
    "# print(\"Joint positions (info):\", info['obs_dict']['qpos'])\n",
    "\n",
    "# print(\"\\nJoint velocities (obs):\", obs[20:40])\n",
    "# print(\"Joint velocities (info):\", info['obs_dict']['qvel'])\n",
    "\n",
    "# print(\"\\nTip position (obs):\", obs[40:43])\n",
    "# print(\"Tip position (info):\", info['obs_dict']['tip_pos'])\n",
    "\n",
    "# print(\"\\nReach error (obs):\", obs[43:46])\n",
    "# print(\"Reach error (info):\", info['obs_dict']['reach_err'])\n",
    "\n",
    "# print(\"\\nMuscle activations (obs):\", obs[46:78])\n",
    "# print(\"Muscle activations (info):\", info['obs_dict']['act'])\n",
    "\n",
    "\n",
    "# # Print joint names\n",
    "# for joint_id in range(env.sim.model.njnt):  # env.sim.model.njnt gives the number of joints\n",
    "#     joint_name = env.sim.model.id2name(joint_id, 'joint')\n",
    "#     print(f\"Joint ID {joint_id}: {joint_name}\")\n",
    "\n",
    "# print(\"\\n\")\n",
    "\n",
    "# # Print actuator (muscle) names\n",
    "# for actuator_id in range(env.sim.model.nu):  # env.sim.model.nu gives the number of actuators\n",
    "#     actuator_name = env.sim.model.id2name(actuator_id, 'actuator')\n",
    "#     print(f\"Actuator ID {actuator_id}: {actuator_name}\")\n",
    "\n",
    "# print(\"\\n\")\n",
    "\n",
    "# # Print site names\n",
    "# for site_id in range(env.sim.model.nsite):  # env.sim.model.nsite gives the number of sites\n",
    "#     site_name = env.sim.model.id2name(site_id, 'site')\n",
    "#     print(f\"Site ID {site_id}: {site_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Index Range** | **Description**               | **Source in info**               |\n",
    "|-----------------|-------------------------------|----------------------------------|\n",
    "| 0:20            | Joint positions (qpos)        | info['obs_dict']['qpos']         |\n",
    "| 20:40           | Joint velocities (qvel)       | info['obs_dict']['qvel']         |\n",
    "| 40:43           | Tip position (tip_pos)        | info['obs_dict']['tip_pos']      |\n",
    "| 43:46           | Reach error (reach_err)       | info['obs_dict']['reach_err']    |\n",
    "| 46:78           | Muscle activations (act)      | info['obs_dict']['act']          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize muscle lengths\n",
    "L_m = torch.ones(n_muscles)\n",
    "\n",
    "# Initialize delayed feedback buffers\n",
    "joint_angle_buffer = [torch.zeros(2) for _ in range(feedback_delay_steps)]\n",
    "joint_velocity_buffer = [torch.zeros(2) for _ in range(feedback_delay_steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NeuralLimbController\n",
    "class NeuralLimbController(nn.Module):\n",
    "    \"\"\"Neural controller for a two-segment limb model.\"\"\"\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs=n_muscles):\n",
    "        \"\"\"Initialize the neural controller.\"\"\"\n",
    "        super(NeuralLimbController, self).__init__()\n",
    "        \n",
    "        # Sensory layer (input layer)\n",
    "        self.w_sr = nn.Parameter(torch.empty(n_s, n_s).uniform_(-1/np.sqrt(n_inputs), 1/np.sqrt(n_inputs)))\n",
    "        self.w_si = nn.Parameter(torch.empty(n_s, n_inputs).uniform_(-1/np.sqrt(n_inputs), 1/np.sqrt(n_inputs)))\n",
    "        self.b_s = nn.Parameter(torch.zeros(n_s))\n",
    "\n",
    "        # M1 layer (output layer)\n",
    "        self.w_mr = nn.Parameter(torch.empty(n_m1, n_m1).uniform_(-1/np.sqrt(n_s), 1/np.sqrt(n_s)))\n",
    "        self.w_mi = nn.Parameter(torch.empty(n_m1, n_s).uniform_(-1/np.sqrt(n_s), 1/np.sqrt(n_s)))\n",
    "        self.b_m = nn.Parameter(torch.zeros(n_m1))\n",
    "        \n",
    "        # Muscle activation layer weights (from M1 to muscle)\n",
    "        self.w_act = nn.Parameter(torch.empty(n_muscles, n_m1).uniform_(-1/np.sqrt(n_m1), 1/np.sqrt(n_m1)))\n",
    "        \n",
    "        # Internal state variables\n",
    "        self.y_s = torch.zeros(n_s)          # Sensory Layer output (y_s(t))\n",
    "        self.y_m = torch.zeros(n_m1)         # M1 Layer output (y_m(t))\n",
    "        self.y_act = torch.zeros(n_muscles)  # Muscle Activation output (y_act(t))\n",
    "    \n",
    "    def neural_activation_step(self, y_t, u_t):\n",
    "        \"\"\"Discretized neural activation dynamics.\"\"\"\n",
    "        return (1 - (dt / tau_n)) * y_t + (dt / tau_n) * torch.tanh(u_t)\n",
    "    \n",
    "    def muscle_activation_step(self, y_act_t, u_act_t):\n",
    "        \"\"\"Discretized muscle activation dynamics.\"\"\"\n",
    "        return (1 - (dt / tau_m)) * y_act_t + (dt / tau_m) * torch.relu(u_act_t)\n",
    "\n",
    "    def forward_step(self, u_fb_t, x_aff_t, y_s_delayed_t):\n",
    "        \"\"\"Perform a single forward step of the neural controller.\"\"\"\n",
    "        # Sensory layer input (u_s) and output (y_s)\n",
    "        u_s = self.w_sr @ y_s_delayed_t + self.w_si @ u_fb_t + self.b_s\n",
    "        self.y_s = self.neural_activation_step(self.y_s, u_s)\n",
    "        \n",
    "        # M1 layer input (u_m) and output (y_m)\n",
    "        u_m = self.w_mr @ self.y_m + self.w_mi @ self.y_s + self.b_m\n",
    "        self.y_m = self.neural_activation_step(self.y_m, u_m)\n",
    "        \n",
    "        # Muscle activation layer input (u_act) and output (y_act)\n",
    "        u_act = self.w_act @ self.y_m + G_s * x_aff_t\n",
    "        self.y_act = self.muscle_activation_step(self.y_act, u_act)\n",
    "        \n",
    "        return self.y_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the neural controller\n",
    "controller = NeuralLimbController(n_inputs=n_inputs, n_outputs=n_muscles)\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.Adam(controller.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, got input (6), mat (6x2), vec (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m pose_err \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(obs[\u001b[38;5;241m8\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Pose error (scalar)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Compute muscle length changes\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m dLm_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mM_m\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mqvel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m L_m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dLm_dt\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;241m*\u001b[39m dt\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Update delayed feedback buffers\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, got input (6), mat (6x2), vec (1)"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 3000\n",
    "for epoch in range(num_epochs):\n",
    "    obs, info = env.reset()\n",
    "    terminated, truncated = False, False\n",
    "    cumulative_cost = 0\n",
    "    step_count = 0\n",
    "\n",
    "    while not (terminated or truncated):\n",
    "        # Extract observation components\n",
    "        qpos = torch.tensor(obs[0], dtype=torch.float32)      # Joint position (scalar)\n",
    "        qvel = torch.tensor(obs[1], dtype=torch.float32)      # Joint velocity (scalar)\n",
    "        act = torch.tensor(obs[2:8], dtype=torch.float32)     # Muscle activations (6 muscles)\n",
    "        pose_err = torch.tensor(obs[8], dtype=torch.float32)  # Pose error (scalar)\n",
    "\n",
    "        # Compute muscle length changes\n",
    "        dLm_dt = - M_m @ qvel.unsqueeze(0)\n",
    "        L_m += dLm_dt.squeeze() * dt\n",
    "\n",
    "        # Update delayed feedback buffers\n",
    "        joint_angle_buffer.append(qpos)\n",
    "        joint_velocity_buffer.append(qvel)\n",
    "        delayed_qpos = joint_angle_buffer.pop(0)\n",
    "        delayed_qvel = joint_velocity_buffer.pop(0)\n",
    "\n",
    "        # Compute muscle forces (F_m) using FL and FV properties\n",
    "        # TODO: Adjust FL and FV to match MyoSuite's muscle model\n",
    "        FL = torch.clamp(1.0 - (L_m - 1.0).pow(2), min=0.0)\n",
    "        FV = torch.clamp(1.0 - dLm_dt.abs(), min=0.0)\n",
    "        F_m = act * FL * FV\n",
    "\n",
    "        # Compute feedback input (u_fb)\n",
    "        position_error = G_p * (delayed_qpos - target_qpos)\n",
    "        velocity_feedback = G_d * delayed_qvel\n",
    "        force_feedback = G_f * F_m\n",
    "        u_fb = torch.cat([position_error.unsqueeze(0), velocity_feedback.unsqueeze(0), force_feedback])\n",
    "\n",
    "        # Compute neural activity cost\n",
    "        neural_cost = controller.y_s.pow(2).mean() + controller.y_m.pow(2).mean()\n",
    "\n",
    "        # Compute force output cost\n",
    "        force_cost = F_m.pow(2).mean()\n",
    "\n",
    "        # Background load kinematic cost\n",
    "        J_b_1 = (qpos - target_qpos).pow(2).mean() + 0.5 * qvel.pow(2).mean()  # [0, T_b]\n",
    "        J_b_2 = (qpos - target_qpos).pow(2).mean() + 0.5 * qvel.pow(2).mean()  # [T_sb, T_p]\n",
    "        J_b = (J_b_1 / Tb) + (J_b_2 / (Tp - Tsb))\n",
    "\n",
    "        # Perturbation load kinematic cost\n",
    "        J_p = (qpos - target_qpos).pow(2).mean() + 0.5 * qvel.pow(2).mean()    # [T_sp, T]\n",
    "        J_p /= (T - Tsp)\n",
    "\n",
    "        # Compute kinematic cost\n",
    "        kinematic_cost = J_b + J_p\n",
    "\n",
    "        # Composite cost function\n",
    "        cost = alpha * neural_cost + beta * force_cost + gamma * kinematic_cost\n",
    "        cumulative_cost += cost.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Generate muscle activations using the neural controller\n",
    "        x_aff_t = torch.zeros(n_muscles)  # Placeholder for afferent feedback\n",
    "        muscle_activations = controller.forward_step(\n",
    "            u_fb_t=u_fb,                  # Feedback input\n",
    "            x_aff_t=x_aff_t,              # Afferent feedback\n",
    "            y_s_delayed_t=controller.y_s  # Delayed sensory layer output\n",
    "        )\n",
    "\n",
    "        # Step the environment\n",
    "        obs, reward, terminated, truncated, info = env.step(muscle_activations.detach().numpy())\n",
    "        step_count += 1\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Cumulative Cost: {cumulative_cost:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensim_scripting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
